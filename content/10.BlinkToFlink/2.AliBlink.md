---
title: "在阿里云Blink上开发应用系统"
chapter: false
weight: 102
---

## 在阿里云Blink上开发应用系统

阿里云的实时计算服务提供了全托管的Blink服务，并在控制台提供了可视化操作工具，包括：FlinkSQL查询编辑器，在线任务提交，任务监控等功能。可以使用户在线编写SQL语句并作为任务进行提交，同时也内置了一些函数，如JSON数据处理等。简化了流式应用的开发和调试。

因此，当客户整体迁移至AWS时，需要将使用托管Blink实现的业务逻辑迁移至原生Flink中（由AWS EMR或Kinesis Analysis提供），需要把客户在阿里云Blink上编写的SQL语句以代码的形式（通常采用Java或Scala语言）进行改写，打包，并在Flink集群上提交任务。

### 客户在阿里云中的应用系统以及SQL语句示例
该应用系统主要通过Blink读取Kafka里的数据，并把读出来的数据做一定转换写入HBase的表中。下面模拟了这个过程。

1.创建表，从Kafka中读取数据，如下面的样例所示：
```
CREATE TABLE kafka_src (
vin STRING,
dateTime STRING,
alarmLevel STRING,
gbdata STRING
) with (
type = 'kafka010',
topic = 'vehiclemessage',
bootstrap.servers='xxx-1.xxx:9092,xxx-2.xxx:9092'
);
```

2.创建HBase目标表，如下面的样例所示：
```
create table hbase_target(
vin varchar,
datetime varchar,
alarmlevel varchar,
gbdata varchar,
primary key (vin)
) with (
type = 'cloudhbase',
zkQuorum='z-1.xxx:2181,z-2.xxx:2818',
columnFamily = '0',
tableName = 'hbase_target',
batchSize = '100'
);
```

3.将读出来的数据写入目标表，在写入目标表之前，可以进行所需要的转换。
```
insert into hbase_target 
select vin, datetime, alarmlevel, gbdata
from kafka_src;
```

### 阿里云Blink流服务的控制台界面
可以在Blink的控制台界面上，把上面描述的数据流的处理逻辑，开发出来。下面显示了一个样例。

1.任务开发 - SQL编辑
![](/images/BlinkToFlink/1025.png)

2.提交任务前的检查与验证

![](/images/BlinkToFlink/1026.png)

3.任务资源配置
![](/images/BlinkToFlink/1027.png)

4.流任务运行监控
![](/images/BlinkToFlink/1028.png)
